{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "436ee7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9e093244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1649445ac70>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 超参数\n",
    "EPOCH = 10  # 训练整批数据的次数\n",
    "\n",
    "LR = 0.001  # 学习率\n",
    "DOWNLOAD_MNIST = True  # 表示还没有下载数据集，如果数据集下载好了就写False\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9bcf471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c4785e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the model to get a higher performance\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()# batch*1*28*28（每次会送入batch个样本，输入通道数1（黑白图像），图像分辨率是28x28）\n",
    "        #in_channels=1,out_channels=8,kernel_size=3,stride=1\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, 1)# 输出数据大小变为28-3+1=26.所以batchx1x28x28 -> batchx8x26x26   \n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, 1)#第一个卷积层的输出通道数等于第二个卷积层的输入通道数。\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(2304, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        ptint(x.shape)\n",
    "        x = F.relu(x)#（激活函数ReLU不改变形状）\n",
    "        x = self.conv2(x)  \n",
    "        x = F.relu(x)#（激活函数ReLU不改变形状）\n",
    "        x = F.max_pool2d(x, 2)# batch*8x26x26  -> batch*8*13*13（2*2的池化层会减半，步长为2）此时输出数据大小变为13-3+2=12（卷积核大小为3），所以 batchx8x13x13 -> batchx16x12x12。\n",
    "        x = torch.flatten(x, 1)\n",
    "        #x = x.view(-1, 16*12*12)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "91964b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader():\n",
    "    # Normalize the input (black and white image)\n",
    "    transform = transforms.Compose([\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
    "     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "     ])   \n",
    "    \n",
    "    # Make train dataset split\n",
    "    train_data = datasets.MNIST(\"mnist-data\", train=True, download=True,\n",
    "                       transform=transform)\n",
    "    # Make test dataset split\n",
    "    test_data = datasets.MNIST(\"mnist-data\", train=False,\n",
    "                       transform=transform)\n",
    "    \n",
    "    \n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7bc04781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_data(test_data):\n",
    "    # 进行测试\n",
    "    testloader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\n",
    "    dataiter = iter(testloader)\n",
    "    images, labels = dataiter.next()\n",
    "    classes = ('0', '1', '2', '3','4', '5', '6', '7', '8', '9')\n",
    "    return images,labels,classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "91138d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_net():\n",
    "    #返回不同的模型\n",
    "    net = Net()                            \n",
    "    #net = torchvision.models.vgg11()      \n",
    "    #net = torchvision.models.vgg11(pretrained=True)    \n",
    "    #net = torchvision.models.googlenet() \n",
    "    #net = torchvision.models.resnet18()   \n",
    "    #net = torchvision.models.resnet18(pretrained=True)   \n",
    "    #for param in net.parameters():#nn.Module有成员函数parameters()\n",
    "        #param.requires_grad = False\n",
    "    # Replace the last fully-connected layer\n",
    "    # Parameters of newly constructed modules have requires_grad=True by default\n",
    "    #net.fc = nn.Linear(512, 1000)#resnet18中有self.fc，作为前向过程的最后一层。\n",
    "    #net = torchvision.models.resnet50()  \n",
    "    #net = torchvision.models.resnet50(pretrained=True)   \n",
    "    #print(net)\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "88b89373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data):\n",
    "    # 批训练 50个samples\n",
    "    # Torch中的DataLoader是用来包装数据的工具，它能帮我们有效迭代数据，这样就可以进行批训练\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True  # 是否打乱数据，一般都打乱\n",
    "    )   \n",
    "    \n",
    "        \n",
    "    # 获取 cnn 网络\n",
    "    net = get_cnn_net()\n",
    "    # 模型加载到gpu中\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = net.to(device)\n",
    "\n",
    "    # 优化器选择Adam\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=LR)\n",
    "    \n",
    "    # 仅更新模型的fc层，默认情况下更新所有的参数\n",
    "    #optimizer = torch.optim.Adam(net.fc.parameters(), lr=LR)\n",
    "    \n",
    "    # 定义损失函数\n",
    "    loss_func = nn.CrossEntropyLoss()  # 目标标签是one-hotted\n",
    "    # 把x和y 都放入Variable中，然后放入cnn中计算output，最后再计算误差\n",
    "    # 开始训练\n",
    "    for epoch in range(EPOCH):\n",
    "        running_loss = 0.0\n",
    "        for step, (inputs, labels) in enumerate(train_loader):  # 分配batch data\n",
    "            # 数据加载到gpu中\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = net(inputs)  # 先将数据放到cnn中计算output\n",
    "            ### 梯度下降算法 ###\n",
    "            loss = loss_func(output, labels)  # 损失函数，输出和真实标签的loss，二者位置不可颠倒\n",
    "            optimizer.zero_grad()  # 清除之前学到的梯度的参数\n",
    "            loss.backward()  # 反向传播，计算梯度\n",
    "            optimizer.step()  # 应用梯度（权重更新）\n",
    "            ### 梯度下降算法 ###\n",
    "            # 数据加载到cpu中\n",
    "            loss = loss.to('cpu')\n",
    "            running_loss += loss.item()         \n",
    "            if step % 50 == 0:   \n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, step + 1, running_loss / 50)) \n",
    "                running_loss = 0.0    \n",
    "    #保存模型\n",
    "    torch.save(net.state_dict(), 'test_cifar_gpu.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d53466ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img /2 + 0.5    # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0e90eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data):\n",
    "    # 获取测试数据集\n",
    "    #images,labels,classes= get_text_data(test_data)\n",
    "    # print images\n",
    "    #imshow(torchvision.utils.make_grid(images))\n",
    "    #print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "    \n",
    "    testloader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=False, num_workers=2)\n",
    "    # 获取cnn网络\n",
    "    net = get_cnn_net()\n",
    "    # 加载模型\n",
    "    net.load_state_dict(torch.load('test_cifar_gpu.pkl'))\n",
    "    # 设置为推理模式\n",
    "    net.eval()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # 模型加载到gpu中\n",
    "    net = net.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            # 数据加载到gpu中\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = net(images)\n",
    "            # 数据加载回cpu\n",
    "            outputs = outputs.to('cpu')\n",
    "            labels  = labels.to('cpu')\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 数据加载\n",
    "    train_data,test_data = dataloader()\n",
    "\n",
    "    # 训练（先训练再预测）\n",
    "    train(train_data)\n",
    "    # 预测（预测前将训练注释掉，否则会再训练一遍）\n",
    "    predict(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
